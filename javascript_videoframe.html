<!DOCTYPE html>

<html>
<head>
<title>AviSynth.VideoFrame</title>
<link rel="stylesheet" type="text/css" href="bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="bootstrap/css/bootstrap-theme.min.css">
</head>
<body>
<div class="container">
<h1 id="AviSynth_VideoFrame">AviSynth.VideoFrame</h1>
<p>The <code>AviSynth.VideoFrame</code> class provides access to a video frame.</p>
<h2 id="Constructors">Constructors</h2>
<p><code>VideoFrame</code>s cannot be directly created at present. They can only be obtained
by using the <code>getFrame(frameNumber)</code> method on an existing <code>Clip</code>. However:</p>
<ul>
<li><code>AviSynth.VideoFrame(width, height, colorspace)</code> - <strong>not implemented yet</strong>
create a new video frame</li>
</ul>
<h2 id="Fields">Fields</h2>
<p>There are two methods to access video frame data, and the fields available
depend on which on is being used.</p>
<ul>
<li><code>interleaved</code> - <code>true</code> if the video data is interleaved</li>
<li><code>planar</code> - <code>true</code> if the video data is planar (YV12 only)</li>
</ul>
<p>If <code>interleaved</code> is <code>true</code>, (which it will be for RGB and YUY2) then you have:</p>
<ul>
<li><code>data</code> - a <code>ArrayBuffer</code> that allows access to the frame data - to actually
use this, you&#39;ll need to create a typed array view into it</li>
<li><code>pitch</code> - the &quot;pitch&quot; (see &quot;accessing a pixel&quot;)</li>
<li><code>rowSize</code> - the &quot;row size&quot; in bytes (see &quot;accessing a pixel&quot;)</li>
<li><code>height</code> - the height, which is simply the height of the frame</li>
<li><code>bitsPerPixel</code> - the number of <strong>bits</strong> in a single pixel, compare with:</li>
<li><code>bytesPerPixel</code> - the number of <strong>bytes</strong> in a single pixel, which only works
for interleaved images (well... see below)</li>
</ul>
<p>Otherwise, if <code>planar</code> is <code>true</code>, those fields are instead available inside:</p>
<ul>
<li><code>y</code> - the Y plane (luma)</li>
<li><code>u</code> - the U plane (green/blue)</li>
<li><code>v</code> - the V plane (red/green)</li>
</ul>
<p><code>ArrayBuffer</code>  is part of a new JavaScript feature that V8 supports called
<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Typed_arrays">JavaScript typed arrays</a>.
Essentially the <code>ArrayBuffer</code> provides an object that represents the data to
JavaScript, while various <code><var>Type</var>Array</code> objects provide
access to the data. (Yes, that link is to the Mozilla documentation. Chrome
doesn&#39;t provide documentation directly. However the Mozilla documentation covers
the standard and, as long as you avoid the Mozilla-specific features, covers the
API available through JSVSynth.)</p>
<p>This means that in order to access the pixel data, you need to write it with
an array view. The simplest one is <code>Uint8Array</code> which provides byte access to
the pixel data.</p>
<p>However, for RGB32 data, you might find it easier to use <code>Uint32Array</code> which
provides you with access to the entire pixels at a time.</p>
<p>In AviSynth, if you have a planar data source, it will be either YV12 or I420
(the difference of which is basically incidental but detectable anyway). This
means that <code>bitPerPixel</code> will be 12 and <code>bytesPerPixel</code> will be an inaccurate
1.</p>
<p><strong>NOTE:</strong> Accessing the <code>data</code> element at all will force
JSVSynth to make the frame &quot;writeable&quot; which will effectively create an extra
copy of the frame. There is currently no way to get read-only access to a frame.</p>
<h2 id="Functions">Functions</h2>
<ul>
<li><code>release()</code> - release the frame data, preventing future access to the frame.
After this is called, the length of the data arrays becomes 0 and you will no
longer be able to access the frame data. <strong>Do not <code>release()</code> a frame you&#39;re
returning from <code>AviSynth.Filter.getFrame()</code>!</strong></li>
<li><code>getContext(type)</code> - based on the <a href="http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html">HTML 5 canvas
API</a>,
this provides access to a context that allows drawing on the frame directly.
At some point you&#39;ll be able to do <code>getContext(&quot;2d&quot;)</code> and get something
similar to a full-fledged
<a href="http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html#canvasrenderingcontext2d"><code>CanvasRenderingContext2D</code></a>.
But for now, you&#39;re stuck with <code>getContext(&quot;simple&quot;)</code>. <strong>Note:</strong> Currently,
rendering contexts are limited to RGB32 clips. This <em>may</em> change in the
future for <code>getContext(&quot;simple&quot;)</code> but will likely never change for
<code>getContext(&quot;2d&quot;)</code>.</li>
<li><code>getPixel(x, y)</code> [EXPERIMENTAL] - get a pixel</li>
</ul>
<h2 id="Accessing_a_Pixel">Accessing a Pixel</h2>
<p>Or, &quot;what&#39;s the difference between pitch and rowSize?&quot;</p>
<p>Basically, data that is provided through the various <code>data</code> arrays may be
&quot;padded&quot; along the side. The simplest reason is when a clip is cropped - rather
than adjust the frame data, AviSynth just marks the new edges and reuses the
frame data. (There are other reasons for this that have to do with data
alignment, but that&#39;s beyond the scope of this page.)</p>
<p>So <code>rowSize</code> gets you the number of &quot;visible&quot; bytes in a row, while <code>pitch</code> is
the number of bytes you need to move forward to the next row of pixels.</p>
<p>This means accessing a specific pixel is done via:</p>
<pre><code class="lang-javascript">frame.data[y * frame.pitch + x * frame.bytesPerPixel]</code></pre>
<p>Techincally, that just gets you the first byte. So, for example, to access all
four channels in an RGB32 clip (RGBA), you&#39;d use:</p>
<pre><code class="lang-javascript">var r = frame.data[y * frame.pitch + x * frame.bytesPerPixel + 2]
var g = frame.data[y * frame.pitch + x * frame.bytesPerPixel + 1]
var b = frame.data[y * frame.pitch + x * frame.bytesPerPixel]
var a = frame.data[y * frame.pitch + x * frame.bytesPerPixel + 3]</code></pre>
<p>This makes more sense when you know that the x86 chips AviSynth runs on are
little-endian, and the data is stored in memory as <code>BGRABGRABGRA...</code>, meaning
that reading a single 32-bit value from a pixel location winds up creating 32
bits in <code>ARGB</code> order, which is the order used for <code>color</code> in <code>BlankClip</code>.</p>
</div>
</body>
</html>
